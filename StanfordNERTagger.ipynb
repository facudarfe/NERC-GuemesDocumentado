{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StanfordNERTagger.ipynb","provenance":[],"authorship_tag":"ABX9TyPROE9z/5meaeYL8LQ7zfy3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ds424a3mM9xM","executionInfo":{"status":"ok","timestamp":1652738408943,"user_tz":180,"elapsed":18907,"user":{"displayName":"Facu Darfe","userId":"05435650411451715325"}},"outputId":"e105ff7d-497d-4efb-db29-f82b8cf87cff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","CARPETA_COLAB = '/content/drive/MyDrive/ProyectoNERC/NERC/'"]},{"cell_type":"code","source":["# Read Guemes documentado dataset\n","tokens = []\n","tags = []\n","with open(CARPETA_COLAB+'dataset/GD-1.conll', 'r', encoding=\"utf-8\") as f:\n","  for line in f:\n","    splitted_line = line.split()\n","    if len(splitted_line) == 3:\n","      tokens.append(splitted_line[0])\n","      tags.append(splitted_line[2])"],"metadata":{"id":"9DKcPltqB9fJ","executionInfo":{"status":"ok","timestamp":1652738417973,"user_tz":180,"elapsed":1192,"user":{"displayName":"Facu Darfe","userId":"05435650411451715325"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Reconocimiento de Entidades Nombradas con Stanford NLP Suite:\n","Ejemplo en español\n","\"\"\"\n","from nltk.tag import StanfordNERTagger\n","from nltk.tokenize import word_tokenize\n","from spacy.lang.es import Spanish\n","import nltk\n","nltk.download('punkt')\n","\n","# Change the path according to your system\n","spanish_classifier = CARPETA_COLAB+'Stanford/spanish.kbp.ancora.distsim.s512.crf.ser.gz'\n","jarfile = CARPETA_COLAB+'Stanford/stanford-ner-3.9.2.jar'\n","\n","# Creating Tagger Object\n","st = StanfordNERTagger(model_filename=spanish_classifier, path_to_jar=jarfile, encoding='utf-8')\n","\n","#tokenized_text = word_tokenize(text)\n","\n","# Tokenizar con spacy (otra manera)\n","#tokenized_text = []\n","#nlp = Spanish()\n","#for token in nlp(text):\n","#  tokenized_text.append(token.text)\n","\n","classified_text = st.tag(tokens)\n","stanford_tags = []\n","for element in classified_text:\n","  stanford_tags.append(element[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFjKIzIQP67R","executionInfo":{"status":"ok","timestamp":1652738435042,"user_tz":180,"elapsed":13943,"user":{"displayName":"Facu Darfe","userId":"05435650411451715325"}},"outputId":"5ee52c54-8750-43ec-fa72-3b345ef6e7e0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n","The StanfordTokenizer will be deprecated in version 3.2.5.\n","Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n","  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"]}]},{"cell_type":"code","source":["true_positive = 0\n","true_negative = 0\n","false_positive = 0\n","false_negative = 0\n","\n","# Medida de precisión\n","for i in range(len(tags)):\n","  if tags[i] != 'O':\n","    if stanford_tags[i] != 'O':\n","      true_positive += 1\n","    else:\n","      false_negative += 1\n","  else:\n","    if stanford_tags[i] != 'O':\n","      false_positive += 1\n","\n","print('Precision:', (true_positive / (true_positive + false_positive)))\n","print('Recall:', (true_positive / (true_positive + false_negative)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zxs-W22f4N5d","executionInfo":{"status":"ok","timestamp":1652739229044,"user_tz":180,"elapsed":273,"user":{"displayName":"Facu Darfe","userId":"05435650411451715325"}},"outputId":"fe298ab8-c556-4bbf-adc6-0f73bb1e6347"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.7006599957419629\n","Recall: 0.5233778625954199\n"]}]},{"cell_type":"code","source":["# Escribir los resultados en un archivo de salida\n","with open(CARPETA_COLAB+'GD-1_Stanford.txt', 'w', encoding=\"utf-8\") as f:\n","  for tupla in classified_text:\n","    f.write(str(tupla)+'\\n')"],"metadata":{"id":"KwGIjFvyTkgP"},"execution_count":null,"outputs":[]}]}